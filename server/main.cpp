/**
 * Auto generated by Archon generator
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 */

#include "idl/RocksdbOnHdfs/gen-archon/RocksdbOnHdfsServer.h"
#include "rocksdb/memtablerep.h"
#include "rocksdb/options.h"
#include "rocksdb/perf_context.h"
#include "rocksdb/perf_level.h"
#include "rocksdb/slice.h"
#include "rocksdb/slice_transform.h"
#include "rocksdb/table.h"
#include "rocksdb/utilities/db_ttl.h"
#include <atomic>
#include <cassert>
#include <cpputil/common/timer/time_cost.h>
#include <cpputil/log/log.h>
#include <cpputil/metrics2/metrics.h>
#include <cpputil/pool/thread_pool.h>
#include <fstream>
#include <functional>
#include <gflags/gflags.h>
#include <iostream>
#include <map>
#include <mutex>
#include <rocksdb/env_hdfs.h>
#include <unordered_set>

DEFINE_string(log4j, "conf/log4j.properties", "log4j file");
DEFINE_string(conf_file, "conf/rocksdb_hdfs.conf", "config file");
DEFINE_string(host, "0.0.0.0", "host for server");
DEFINE_int32(port, 9993, "port for server");
DEFINE_int32(io, 10, "io thread number for server");
DEFINE_int32(worker, 40, "worker thread number for server");

class NoopTransform : public rocksdb::SliceTransform {
public:
  explicit NoopTransform() {}

  virtual const char *Name() const override { return "rocksdb.Noop"; }

  virtual rocksdb::Slice Transform(const rocksdb::Slice &src) const override {
    return src;
  }

  virtual bool InDomain(const rocksdb::Slice &src) const override {
    return true;
  }

  virtual bool InRange(const rocksdb::Slice &dst) const override {
    return true;
  }

  virtual bool
  SameResultWhenAppended(const rocksdb::Slice &prefix) const override {
    return false;
  }
};

//对rocksdb, cache,iters和offset的封装
struct openObj {
  const int step = 5e3; // cache容量，去掉value之后可以加大。
  rocksdb::DBWithTTL *db = nullptr;
  std::vector<rocksdb::Iterator *> iters;
  std::vector<rocksdb::ColumnFamilyHandle *> cfhs;
  std::unordered_map<std::string, rocksdb_hdfs::Value> cache;
  std::mutex cache_lock;
  time_t ts = 0; // 用于关闭过期DB
  int offset = 0;
  std::mutex scan_lock; // 锁定整个scan过程，避免重复scan。
  bool eof() {          // assert(is_held(scan_lock)),这一点是确定的
    for (const auto &it : iters)
      if (it->Valid())
        return false;
    return true;
  }
  bool iter_status() { //同eof(),assert(is_held(scan_lock))
    for (const auto &it : iters)
      if (!it->status().ok())
        return false;
    return true;
  }
  openObj() {}
  openObj(int cf) {
    iters.reserve(cf);
    cfhs.reserve(cf);
    cache.reserve(step);
  }
  ~openObj() {
    if (!iters.empty()) {
      for (auto &iter : iters)
        if (iter)
          delete iter;
      iters.clear();
    }
    if (!cfhs.empty()) {
      for (auto &cfh : cfhs)
        if (cfh)
          delete cfh;
      cfhs.clear();
    }
    if (!cache.empty())
      cache.clear();
    if (db)
      delete db;
  }
};

class RocksdbOnHdfsHandler
    : public ::rocksdb_hdfs::archon::RocksdbOnHdfsHandler {
public:
  RocksdbOnHdfsHandler() {}
  ~RocksdbOnHdfsHandler() {}

  int open(::rocksdb_hdfs::OpenRsp &rsp, const ::rocksdb_hdfs::OpenReq &req,
           std::shared_ptr<::archon::common::RequestContext> ctx) override {
    // 此处填写业务代码
    if (is_opening(req.hdfs_path)) {
      rsp.status.message = "Opening";
      return -1;
    }
    if (is_opened(req.hdfs_path)) {
      rsp.status.message = "Opened";
      return -1;
    }
    {
      std::lock_guard<std::mutex> lg(opening_lock);
      opening.insert(req.hdfs_path);
    }
    async_open(std::make_shared<::rocksdb_hdfs::OpenRsp>(rsp),
               std::make_shared<::rocksdb_hdfs::OpenReq>(req));
    return 0;
  }

  int openStatus(
      ::rocksdb_hdfs::OpenStatusRsp &rsp,
      const ::rocksdb_hdfs::OpenStatusReq &req,
      std::shared_ptr<::archon::common::RequestContext> ctx) override {
    // 此处填写业务代码
    if (is_opening(req.hdfs_path)) {
      rsp.status.message = "Opening";
      return 0;
    }
    if (is_opened(req.hdfs_path))
      rsp.status.message = "Opened";
    else if (is_failed(req.hdfs_path)) {
      std::lock_guard<std::mutex> lg(failed_lock);
      rsp.status.message = "Failed.\n" + failed[req.hdfs_path];
    } else
      rsp.status.message = "NeverOpened";
    return -1; // client收到-1终止轮询
  }

  int scan(::rocksdb_hdfs::ScanRsp &rsp, const ::rocksdb_hdfs::ScanReq &req,
           std::shared_ptr<::archon::common::RequestContext> ctx) override {
    // 此处填写业务代码
    if (!is_opened(req.hdfs_path)) {
      if (is_opening(req.hdfs_path))
        rsp.status.message = "Opening DB, please wait.";
      else if (is_failed(req.hdfs_path))
        rsp.status.message = "DB open failed last time.";
      else
        rsp.status.message = "DB has never opened on this pod";
      return -1; //-1表示终止client侧scan
    }
    assert(!is_opening(req.hdfs_path)); //不可能存在同时opened和opening两种状态
    openObj *obj = nullptr;
    {
      std::lock_guard<std::mutex> lg(opened_lock);
      obj = opened[req.hdfs_path];
    }
    assert(obj);

    if (!obj->scan_lock.try_lock()) {
      rsp.status.message =
          "One scan routine is undergoing, please wait until it finish.";
      return -1;
    }
    // assert(obj->iter_status() && !obj->eof());
    // 检查offset
    if (req.begin_offset < obj->offset - obj->step ||
        req.begin_offset > obj->offset) { //超出cache范围
      if (req.begin_offset < obj->offset - obj->step)
        rsp.status.message = "Outdated data, if you want that data, close DB "
                             "and read from start.";
      else
        rsp.status.message = "Offset exceed limit.";
      obj->scan_lock.unlock();
      return -1;
    }
    // assert(req.begin_offset == obj->offset - obj->step || req.begin_offset ==
    // obj->offset);//client端保证
    if (req.begin_offset == obj->offset - obj->step) { //重传cache
      rsp.kvs = std::map<std::string, rocksdb_hdfs::Value>(obj->cache.begin(),
                                                           obj->cache.end());
      rsp.status.message = "Resend ok";
      rsp.end_offset = obj->offset;
      obj->scan_lock.unlock();
      return 0;
    }
    obj->cache.clear();
    obj->cache.reserve(obj->step);
    cpputil::TimeCost tc1;
    cpputil::pool::ThreadPool tp(20);
    std::vector<std::function<void()>> func_list;
    //按照CF粒度多线程读取
    for (const auto &it : obj->iters) {
      auto func = [&]() {
        for (; it->Valid(); it->Next()) {
          std::lock_guard<std::mutex> lg(obj->cache_lock);
          assert(obj->cache.size() <= obj->step);
          if (obj->cache.size() == obj->step)
            break;
          rocksdb_hdfs::Value val;
          // val.value = it->value().ToString();value极大，暂时舍弃
          // val.ts = 0;
          // it->timestamp(val.ts);
          obj->cache.emplace(it->key().ToString(), val);
        }
      };
      func_list.emplace_back(std::move(func));
    }
    tp.concurrent_run(func_list);
    if (!obj->iter_status()) {
      rsp.status.message = "Something wrong with iter (maybe HDFS has "
                           "been closed). Check HDFS status.";
      obj->scan_lock.unlock();
      return -1;
    }
    std::cerr << "====================Concurrent read finish, time cost "
              << tc1.get_elapsed() / (1000 * 1000 * 1.0 * 3600) << std::endl;
    obj->offset += obj->cache.size();
    rsp.kvs = std::map<std::string, rocksdb_hdfs::Value>(obj->cache.begin(),
                                                         obj->cache.end());
    rsp.status.message = obj->eof() ? "eof, ok" : "ok";
    rsp.end_offset = obj->offset;
    obj->scan_lock.unlock();
    return 0;
  }

  int close(::rocksdb_hdfs::CloseRsp &rsp, const ::rocksdb_hdfs::CloseReq &req,
            std::shared_ptr<::archon::common::RequestContext> ctx) override {
    // 此处填写业务代码
    if (!is_opened(req.hdfs_path)) {
      rsp.status.message = "This DB havn't been opened.";
      return -1;
    }
    assert(!is_opening(req.hdfs_path));
    std::lock_guard<std::mutex> lg(opened_lock);
    if (!opened[req.hdfs_path]->scan_lock.try_lock()) {
      rsp.status.message = "One scan routine is undergoing, please wait "
                           "until it finish in case to cause a core dump. Or "
                           "quit scan manually.";
      return -1;
    }
    delete opened[req.hdfs_path];
    opened.erase(req.hdfs_path);
    rsp.status.message = "Successfully close DB and release related resourses";
    return 0;
  }
  //关闭index后scan效率得到提升，但是get会出core
  int get(::rocksdb_hdfs::GetRsp &rsp, const ::rocksdb_hdfs::GetReq &req,
          std::shared_ptr<::archon::common::RequestContext> ctx) override {
    // 此处填写业务代码
    if (!is_opened(req.hdfs_path)) {
      if (is_opening(req.hdfs_path))
        rsp.status.message = "Opening DB, please wait.";
      else
        rsp.status.message = "DB haven't been opened. Please open it first.";
      return -1;
    }
    assert(!is_opening(req.hdfs_path)); //不可能存在同时opened和opening两种状态
    openObj *obj = nullptr;
    {
      std::lock_guard<std::mutex> lg(opened_lock);
      obj = opened[req.hdfs_path];
    }
    assert(obj);
    rocksdb::Status s;
    for (const auto &key : req.key) {
      rocksdb_hdfs::Value val;
      for (const auto &cfh : obj->cfhs) {
        s = obj->db->Get(rocksdb::ReadOptions(), cfh, key, &(val.value));
        if (s.ok()) {
          rsp.kvs.emplace(key, val);
          break;
        }
      }
    }
    return 0;
  }

private:
  //三个有锁集合，分别为opening，opened和failed,opened关联openObj对象,failed关联rocksdb::status.ToString()
  std::unordered_set<std::string> opening;
  std::unordered_map<std::string, openObj *> opened;
  std::unordered_map<std::string, std::string> failed;
  std::mutex opening_lock, opened_lock, failed_lock;
  bool is_opening(std::string hdfs_path) {
    std::lock_guard<std::mutex> lg(opening_lock);
    return opening.find(hdfs_path) != opening.end();
  }
  bool is_opened(std::string hdfs_path) {
    std::lock_guard<std::mutex> lg(opened_lock);
    return opened.find(hdfs_path) != opened.end();
  }
  bool is_failed(std::string hdfs_path) {
    std::lock_guard<std::mutex> lg(failed_lock);
    return failed.find(hdfs_path) != failed.end();
  }
  void async_open(std::shared_ptr<::rocksdb_hdfs::OpenRsp> rsp,
                  std::shared_ptr<::rocksdb_hdfs::OpenReq> req) {
    auto open_func = [=]() {
      pthread_setname_np(pthread_self(), "open");
      std::cerr << "================open path========================"
                << req->hdfs_path << std::endl;
      auto obj = new openObj();
      rocksdb::DBOptions dboptions;
      rocksdb::ColumnFamilyOptions cfoptions;
      rocksdb::PlainTableOptions ptoptions;
      rocksdb::Status s;
      cpputil::TimeCost tc;
      try {
        s = rocksdb::NewHdfsEnv(&dboptions.env, req->hdfs_host);
      } catch (rocksdb::HdfsFatalException &e) {
        std::cerr << "==============" << e.what()
                  << "=================" << std::endl;
      }
      std::cerr << "=============Connect " << s.ToString()
                << "==============" << std::endl;
      if (!s.ok()) {
        rsp->status.message =
            "Connect HDFS fail,please check your host and path.\n" +
            s.ToString();
        {
          std::lock_guard<std::mutex> lg(opening_lock);
          std::lock_guard<std::mutex> lg_(failed_lock);
          failed[req->hdfs_path] = s.ToString();
          opening.erase(req->hdfs_path);
        }
        delete obj;
        return -1;
      }
      cfoptions.disable_auto_compactions = true;
      dboptions.create_if_missing = false;
      dboptions.create_missing_column_families = false;
      dboptions.max_open_files = 2;
      dboptions.max_log_file_size = 32 << 20;
      dboptions.keep_log_file_num = 2;
      dboptions.max_manifest_file_size = 32 << 20;
      dboptions.stats_dump_period_sec = 600;
      dboptions.WAL_ttl_seconds = 1800;
      dboptions.advise_random_on_open = false; // FIXME
      dboptions.max_background_jobs = 20;
      dboptions.use_adaptive_mutex = true;
      dboptions.delete_obsolete_files_period_micros = 600 * 1000000;
      dboptions.max_file_opening_threads = 100;
      dboptions.allow_concurrent_memtable_write = false;
      cfoptions.prefix_extractor.reset(new NoopTransform());
      cfoptions.memtable_factory.reset(
          rocksdb::NewHashLinkListRepFactory(1 << 18, 0, 64, true, 32));
      ptoptions.index_sparseness = 1;
      ptoptions.hash_table_ratio = 0.8;
      ptoptions.bloom_bits_per_key = 0;
      ptoptions.full_scan_mode = true;
      {
        cfoptions.num_levels = 5;
        cfoptions.write_buffer_size = 128 << 20;
        cfoptions.target_file_size_base = 32 << 20;
        cfoptions.max_bytes_for_level_multiplier = 4;
        //减小空间放大
        cfoptions.level_compaction_dynamic_level_bytes = true;
      }
      cfoptions.table_factory.reset(rocksdb::NewPlainTableFactory(ptoptions));
      std::vector<int32_t> ttls(req->cf_num, 86400 * 3);
      std::vector<rocksdb::ColumnFamilyDescriptor> cfds;
      cfds.emplace_back(rocksdb::kDefaultColumnFamilyName, cfoptions);
      for (int i = 0; i < req->cf_num - 1; ++i)
        cfds.emplace_back(std::to_string(i), cfoptions);
      std::cerr << "=====================Start Openning====================="
                << std::endl;

      auto status =
          rocksdb::DBWithTTL::Open(dboptions, req->hdfs_path, cfds,
                                   &(obj->cfhs), &(obj->db), ttls, true);
      if (status.ok()) {
        std::cerr << "====================open success, time cost "
                  << tc.get_elapsed() / (1000 * 1000 * 1.0 * 3600)
                  << " h=====================" << std::endl;
        rsp->status.message = "Open success!";
        s = obj->db->NewIterators(rocksdb::ReadOptions(), obj->cfhs,
                                  &(obj->iters));
        if (!s.ok()) {
          rsp->status.message =
              "Get iters fail,please try again.\n" + s.ToString();
          {
            std::lock_guard<std::mutex> lg(opening_lock);
            std::lock_guard<std::mutex> lg_(failed_lock);
            failed[req->hdfs_path] = s.ToString();
            opening.erase(req->hdfs_path);
          }
          delete obj;
          return -1;
        }
        for (const auto &it : obj->iters)
          it->SeekToFirst();
        obj->ts = time(nullptr);
        obj->db->SetDBOptions({{"max_open_files", "-1"}});
        { //从opening转移到opened
          std::lock_guard<std::mutex> lg_(opening_lock);
          std::lock_guard<std::mutex> lg(opened_lock);
          opening.erase(req->hdfs_path);
          opened[req->hdfs_path] = obj;
        }
        return 0;
      } else {
        rsp->status.message =
            "Open fail,please try again.\n" + status.ToString();
        {
          std::lock_guard<std::mutex> lg(opening_lock);
          std::lock_guard<std::mutex> lg_(failed_lock);
          opening.erase(req->hdfs_path);
          failed[req->hdfs_path] = status.ToString();
        }
        delete obj;
        return -1;
      }
    };
    std::thread open_thread(open_func);
    open_thread.detach();
  }
};

int main(int argc, char **argv) {
  using ::rocksdb_hdfs::archon::RocksdbOnHdfsServer;

  google::ParseCommandLineFlags(&argc, &argv, true);
  cpputil::log::init(FLAGS_log4j);
  cpputil::program::Conf conf(FLAGS_conf_file);
  cpputil::metrics2::Metrics::init(conf);
  archon::common::ArchonContext::init(conf);
  std::string port_str = conf.get("server_port");
  const char *port_env = std::getenv("PORT0");
  if (port_env != nullptr) {
    port_str = port_env;
  }
  int port = std::stoi(port_str);
  auto handler = std::make_shared<RocksdbOnHdfsHandler>();
  auto server = RocksdbOnHdfsServer::create_server(
      "auto_generated_RocksdbOnHdfs",
      archon::server::ACL::AllowNonStandardRequest, handler, FLAGS_host, port,
      FLAGS_worker);

  server->setNumIOWorkerThreads(FLAGS_io);
  server->serve();
  return 0;
}
